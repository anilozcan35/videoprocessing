{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "\n",
    "import dataloader as dataloader\n",
    "import utils\n",
    "\n",
    "import time\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(dataloader)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLSTM(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNLSTM, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv3d(3, 32, kernel_size=(3, 3, 3), padding=(2, 2, 2))\n",
    "        self.conv2 = nn.Conv3d(32, 64, kernel_size=(3, 3, 3), padding=(2, 2, 2))\n",
    "        \n",
    "        self.pool = nn.MaxPool3d(kernel_size=(5, 5, 5))\n",
    "\n",
    "        # Calculate input size for LSTM\n",
    "        self.input_size = 64 * 1 * 1\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=self.input_size, hidden_size=512, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, C, H, W, timesteps = x.size()\n",
    "\n",
    "        c_in = x\n",
    "        \n",
    "        c_out = self.pool(torch.relu(self.conv1(c_in)))\n",
    "        c_out = self.pool(torch.relu(self.conv2(c_out)))\n",
    "        \n",
    "        r_in = c_out.view(batch_size, timesteps, -1)\n",
    "        \n",
    "        r_out, (h_n, h_c) = self.lstm(r_in)\n",
    "        r_out = self.fc(r_out[:, -1, :])\n",
    "        \n",
    "        return r_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNNLSTM(\n",
      "  (conv1): Conv3d(3, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2))\n",
      "  (conv2): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(2, 2, 2))\n",
      "  (pool): MaxPool3d(kernel_size=(5, 5, 5), stride=(5, 5, 5), padding=0, dilation=1, ceil_mode=False)\n",
      "  (lstm): LSTM(64, 512, batch_first=True, bidirectional=True)\n",
      "  (fc): Linear(in_features=1024, out_features=5, bias=True)\n",
      ")\n",
      "Output shape: torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "# Example usage with dummy data\n",
    "\n",
    "## model initialization\n",
    "model = CNNLSTM(num_classes=5).to(device)\n",
    "print(model)\n",
    "\n",
    "## Generate random dummy input data within the defined shape\n",
    "dummy_data = torch.randn(2, 3, 112, 112, 16).to(device)  # Batch size, channels, height, width, frames\n",
    "\n",
    "## Forward pass through the model\n",
    "output = model(dummy_data)\n",
    "\n",
    "# Print the output shape\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "CNNLSTM                                  --\n",
       "├─Conv3d: 1-1                            2,624\n",
       "├─Conv3d: 1-2                            55,360\n",
       "├─MaxPool3d: 1-3                         --\n",
       "├─LSTM: 1-4                              2,367,488\n",
       "├─Linear: 1-5                            5,125\n",
       "=================================================================\n",
       "Total params: 2,430,597\n",
       "Trainable params: 2,430,597\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print model summary\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialize dataloader\n",
    "\n",
    "# Define your transform (data pre-processing) fınction\n",
    "# Define your dataset with transform\n",
    "transform = transforms.Compose([\n",
    "    dataloader.myUCF5Preprocessing(output_size=(112, 112))\n",
    "])\n",
    "\n",
    "\n",
    "# Define your dataset\n",
    "dataset = dataloader.myUCF5Loader(root_dir='UCF5', transform=transform)\n",
    "\n",
    "\n",
    "# Split the dataset\n",
    "train_set, val_set, test_set = dataloader.split_dataset(dataset)\n",
    "\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=2, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=1, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\citak\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\io\\video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n",
      "  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Train Loss: 1.6576, Val Loss: 1.6240, Val Acc: 10.00%\n",
      "Epoch [2/3], Train Loss: 1.6073, Val Loss: 1.6444, Val Acc: 10.00%\n",
      "Epoch [3/3], Train Loss: 1.6032, Val Loss: 1.5843, Val Acc: 20.00%\n",
      "Test Loss: 1.5254, Test Acc: 30.00%\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "\n",
    "# hyper-params\n",
    "num_epochs = 3\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# dont forget to send model to device \n",
    "model.to(device) \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device, dtype=torch.float32), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device, dtype=torch.float32), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "          f\"Train Loss: {running_loss / len(train_loader.dataset):.4f}, \"\n",
    "          f\"Val Loss: {val_loss / len(val_loader.dataset):.4f}, \"\n",
    "          f\"Val Acc: {(100 * correct / total):.2f}%\")\n",
    "\n",
    "# Testing loop\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device, dtype=torch.float32), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "print(f\"Test Loss: {test_loss / len(test_loader.dataset):.4f}, \"\n",
    "      f\"Test Acc: {(100 * correct / total):.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
