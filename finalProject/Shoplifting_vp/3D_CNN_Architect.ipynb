{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","mount_file_id":"1r9Izz24SwQcrt9C-cqJ8m7tgaF1gokn_","authorship_tag":"ABX9TyMPrPIK4pJvTzTRuuBZBts7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install torchinfo\n","!pip install av"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sdNDkRTFnlg5","executionInfo":{"status":"ok","timestamp":1715621265577,"user_tz":-180,"elapsed":13231,"user":{"displayName":"Anıl Özcan","userId":"06510389857538456980"}},"outputId":"dad3d5ec-33d8-498e-fef4-31354dab58d3"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchinfo\n","  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n","Installing collected packages: torchinfo\n","Successfully installed torchinfo-1.8.0\n","Collecting av\n","  Downloading av-12.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: av\n","Successfully installed av-12.0.0\n"]}]},{"cell_type":"code","source":["# get data\n","!wget https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/r3yjf35hzr-1.zip\n","!unzip r3yjf35hzr-1.zip -d ./\n","!mv 'Shoplifting Dataset (2022) - CV Laboratory MNNIT Allahabad' shopliftingdata\n","!unzip /content/shopliftingdata/Dataset.zip -d ./\n","!cd /content/Dataset\n","!pip install -U kora"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"oTkfN5Gb3UbP","executionInfo":{"status":"ok","timestamp":1715621310170,"user_tz":-180,"elapsed":44608,"user":{"displayName":"Anıl Özcan","userId":"06510389857538456980"}},"outputId":"8f215ee8-d8fd-48f7-b005-45b3967e96af"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-05-13 17:27:45--  https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/r3yjf35hzr-1.zip\n","Resolving prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com (prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com)... 3.5.67.193, 3.5.70.198, 52.218.25.184, ...\n","Connecting to prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com (prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com)|3.5.67.193|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 760777897 (726M) [application/zip]\n","Saving to: ‘r3yjf35hzr-1.zip’\n","\n","r3yjf35hzr-1.zip    100%[===================>] 725.53M  29.5MB/s    in 25s     \n","\n","2024-05-13 17:28:10 (28.6 MB/s) - ‘r3yjf35hzr-1.zip’ saved [760777897/760777897]\n","\n","Archive:  r3yjf35hzr-1.zip\n","  inflating: ./Shoplifting Dataset (2022) - CV Laboratory MNNIT Allahabad/Dataset.zip  \n","Archive:  /content/shopliftingdata/Dataset.zip\n","   creating: ./Dataset/\n","   creating: ./Dataset/Normal/\n","  inflating: ./Dataset/Normal/Normal (1).mp4  \n","  inflating: ./Dataset/Normal/Normal (10).mp4  \n","  inflating: ./Dataset/Normal/Normal (11).mp4  \n","  inflating: ./Dataset/Normal/Normal (12).mp4  \n","  inflating: ./Dataset/Normal/Normal (13).mp4  \n","  inflating: ./Dataset/Normal/Normal (14).mp4  \n","  inflating: ./Dataset/Normal/Normal (15).mp4  \n","  inflating: ./Dataset/Normal/Normal (16).mp4  \n","  inflating: ./Dataset/Normal/Normal (17).mp4  \n","  inflating: ./Dataset/Normal/Normal (18).mp4  \n","  inflating: ./Dataset/Normal/Normal (19).mp4  \n","  inflating: ./Dataset/Normal/Normal (2).mp4  \n","  inflating: ./Dataset/Normal/Normal (20).mp4  \n","  inflating: ./Dataset/Normal/Normal (21).mp4  \n","  inflating: ./Dataset/Normal/Normal (22).mp4  \n","  inflating: ./Dataset/Normal/Normal (23).mp4  \n","  inflating: ./Dataset/Normal/Normal (24).mp4  \n","  inflating: ./Dataset/Normal/Normal (25).mp4  \n","  inflating: ./Dataset/Normal/Normal (26).mp4  \n","  inflating: ./Dataset/Normal/Normal (27).mp4  \n","  inflating: ./Dataset/Normal/Normal (28).mp4  \n","  inflating: ./Dataset/Normal/Normal (29).mp4  \n","  inflating: ./Dataset/Normal/Normal (3).mp4  \n","  inflating: ./Dataset/Normal/Normal (30).mp4  \n","  inflating: ./Dataset/Normal/Normal (31).mp4  \n","  inflating: ./Dataset/Normal/Normal (32).mp4  \n","  inflating: ./Dataset/Normal/Normal (33).mp4  \n","  inflating: ./Dataset/Normal/Normal (34).mp4  \n","  inflating: ./Dataset/Normal/Normal (35).mp4  \n","  inflating: ./Dataset/Normal/Normal (36).mp4  \n","  inflating: ./Dataset/Normal/Normal (37).mp4  \n","  inflating: ./Dataset/Normal/Normal (38).mp4  \n","  inflating: ./Dataset/Normal/Normal (39).mp4  \n","  inflating: ./Dataset/Normal/Normal (4).mp4  \n","  inflating: ./Dataset/Normal/Normal (40).mp4  \n","  inflating: ./Dataset/Normal/Normal (41).mp4  \n","  inflating: ./Dataset/Normal/Normal (42).mp4  \n","  inflating: ./Dataset/Normal/Normal (43).mp4  \n","  inflating: ./Dataset/Normal/Normal (44).mp4  \n","  inflating: ./Dataset/Normal/Normal (45).mp4  \n","  inflating: ./Dataset/Normal/Normal (46).mp4  \n","  inflating: ./Dataset/Normal/Normal (47).mp4  \n","  inflating: ./Dataset/Normal/Normal (48).mp4  \n","  inflating: ./Dataset/Normal/Normal (49).mp4  \n","  inflating: ./Dataset/Normal/Normal (5).mp4  \n","  inflating: ./Dataset/Normal/Normal (50).mp4  \n","  inflating: ./Dataset/Normal/Normal (51).mp4  \n","  inflating: ./Dataset/Normal/Normal (52).mp4  \n","  inflating: ./Dataset/Normal/Normal (53).mp4  \n","  inflating: ./Dataset/Normal/Normal (54).mp4  \n","  inflating: ./Dataset/Normal/Normal (55).mp4  \n","  inflating: ./Dataset/Normal/Normal (56).mp4  \n","  inflating: ./Dataset/Normal/Normal (57).mp4  \n","  inflating: ./Dataset/Normal/Normal (58).mp4  \n","  inflating: ./Dataset/Normal/Normal (59).mp4  \n","  inflating: ./Dataset/Normal/Normal (6).mp4  \n","  inflating: ./Dataset/Normal/Normal (60).mp4  \n","  inflating: ./Dataset/Normal/Normal (61).mp4  \n","  inflating: ./Dataset/Normal/Normal (62).mp4  \n","  inflating: ./Dataset/Normal/Normal (63).mp4  \n","  inflating: ./Dataset/Normal/Normal (64).mp4  \n","  inflating: ./Dataset/Normal/Normal (65).mp4  \n","  inflating: ./Dataset/Normal/Normal (66).mp4  \n","  inflating: ./Dataset/Normal/Normal (67).mp4  \n","  inflating: ./Dataset/Normal/Normal (68).mp4  \n","  inflating: ./Dataset/Normal/Normal (69).mp4  \n","  inflating: ./Dataset/Normal/Normal (7).mp4  \n","  inflating: ./Dataset/Normal/Normal (70).mp4  \n","  inflating: ./Dataset/Normal/Normal (71).mp4  \n","  inflating: ./Dataset/Normal/Normal (72).mp4  \n","  inflating: ./Dataset/Normal/Normal (73).mp4  \n","  inflating: ./Dataset/Normal/Normal (74).mp4  \n","  inflating: ./Dataset/Normal/Normal (75).mp4  \n","  inflating: ./Dataset/Normal/Normal (76).mp4  \n","  inflating: ./Dataset/Normal/Normal (77).mp4  \n","  inflating: ./Dataset/Normal/Normal (78).mp4  \n","  inflating: ./Dataset/Normal/Normal (79).mp4  \n","  inflating: ./Dataset/Normal/Normal (8).mp4  \n","  inflating: ./Dataset/Normal/Normal (80).mp4  \n","  inflating: ./Dataset/Normal/Normal (81).mp4  \n","  inflating: ./Dataset/Normal/Normal (82).mp4  \n","  inflating: ./Dataset/Normal/Normal (83).mp4  \n","  inflating: ./Dataset/Normal/Normal (84).mp4  \n","  inflating: ./Dataset/Normal/Normal (85).mp4  \n","  inflating: ./Dataset/Normal/Normal (86).mp4  \n","  inflating: ./Dataset/Normal/Normal (87).mp4  \n","  inflating: ./Dataset/Normal/Normal (88).mp4  \n","  inflating: ./Dataset/Normal/Normal (89).mp4  \n","  inflating: ./Dataset/Normal/Normal (9).mp4  \n","  inflating: ./Dataset/Normal/Normal (90).mp4  \n","   creating: ./Dataset/Shoplifting/\n","  inflating: ./Dataset/Shoplifting/Shoplifting (1).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (10).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (11).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (12).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (13).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (14).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (15).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (16).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (17).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (18).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (19).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (2).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (20).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (21).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (22).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (23).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (24).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (25).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (26).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (27).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (28).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (29).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (3).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (30).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (31).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (32).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (33).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (34).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (35).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (36).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (37).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (38).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (39).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (4).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (40).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (41).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (42).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (43).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (44).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (45).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (46).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (47).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (48).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (5).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (50).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (51).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (52).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (53).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (54).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (55).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (56).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (57).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (58).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (59).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (6).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (60).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (61).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (62).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (63).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (64).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (65).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (66).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (67).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (68).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (69).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (7).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (70).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (71).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (72).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (73).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (74).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (75).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (76).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (77).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (78).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (79).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (8).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (80).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (81).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (82).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (83).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (84).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (85).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (86).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (87).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (88).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (89).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (9).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (90).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (91).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (92).mp4  \n","  inflating: ./Dataset/Shoplifting/Shoplifting (93).mp4  \n","Collecting kora\n","  Downloading kora-0.9.20-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from kora) (7.34.0)\n","Requirement already satisfied: fastcore in /usr/local/lib/python3.10/dist-packages (from kora) (1.5.33)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastcore->kora) (24.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (67.7.2)\n","Collecting jedi>=0.16 (from ipython->kora)\n","  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (3.0.43)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (2.16.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->kora) (4.9.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->kora) (0.8.4)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->kora) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->kora) (0.2.13)\n","Installing collected packages: jedi, kora\n","Successfully installed jedi-0.19.1 kora-0.9.20\n"]}]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/drive/MyDrive/Video Processing/finalProject/Shoplifting_vp')"],"metadata":{"id":"9kdmzTyloAkL","executionInfo":{"status":"ok","timestamp":1715621310370,"user_tz":-180,"elapsed":227,"user":{"displayName":"Anıl Özcan","userId":"06510389857538456980"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"collapsed":true,"id":"s7HG0DQanQee","executionInfo":{"status":"ok","timestamp":1715621317617,"user_tz":-180,"elapsed":7463,"user":{"displayName":"Anıl Özcan","userId":"06510389857538456980"}}},"outputs":[],"source":["# importların yapılması\n","import os\n","import numpy as np\n","import gc\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","from copy import deepcopy\n","from torchinfo import summary\n","\n","import dataloader as dataloader\n","import utils as utils\n","\n","import time\n","import importlib"]},{"cell_type":"code","source":["importlib.reload(dataloader)\n","importlib.reload(utils)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"LvL_096InkO4","executionInfo":{"status":"ok","timestamp":1715621317617,"user_tz":-180,"elapsed":7,"user":{"displayName":"Anıl Özcan","userId":"06510389857538456980"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IM_S5-5Yk0zR","executionInfo":{"status":"ok","timestamp":1715621317618,"user_tz":-180,"elapsed":8,"user":{"displayName":"Anıl Özcan","userId":"06510389857538456980"}},"outputId":"e73e7085-4eaa-465d-b387-0bc1c1c45f9f"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["## initialize dataloader\n","\n","# Define your transform (data pre-processing) fınction\n","# Define your dataset with transform\n","transform = transforms.Compose([\n","    dataloader.ShopliftingPreprocessing(output_size=(120, 120))\n","])\n"],"metadata":{"id":"nf8V8VPOqwLs","executionInfo":{"status":"ok","timestamp":1715621317618,"user_tz":-180,"elapsed":6,"user":{"displayName":"Anıl Özcan","userId":"06510389857538456980"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Define your dataset\n","dataset = dataloader.ShopliftingDataLoader(root_dir='Dataset', transform=transform)"],"metadata":{"collapsed":true,"id":"FwzfKOeOq4OX","executionInfo":{"status":"ok","timestamp":1715621317618,"user_tz":-180,"elapsed":5,"user":{"displayName":"Anıl Özcan","userId":"06510389857538456980"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["dataset.samples[35]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5fqFupWdCtTq","executionInfo":{"status":"ok","timestamp":1715621317618,"user_tz":-180,"elapsed":5,"user":{"displayName":"Anıl Özcan","userId":"06510389857538456980"}},"outputId":"35fd2178-bb17-45d6-b2fe-2ab3188a4ac9"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('Dataset/Normal/Normal (41).mp4', 0)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["dataset.__getitem__(35)[0].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KWFOFy0AEA_p","executionInfo":{"status":"ok","timestamp":1715621318498,"user_tz":-180,"elapsed":883,"user":{"displayName":"Anıl Özcan","userId":"06510389857538456980"}},"outputId":"9539965f-1d41-4654-d46c-fea931441e95"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/io/video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"]},{"output_type":"execute_result","data":{"text/plain":["(3, 120, 120, 30)"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Split the dataset\n","train_set, val_set, test_set = dataloader.split_dataset(dataset)"],"metadata":{"id":"duN1KLQA6H-_","executionInfo":{"status":"ok","timestamp":1715621319013,"user_tz":-180,"elapsed":520,"user":{"displayName":"Anıl Özcan","userId":"06510389857538456980"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["len(train_set), len(val_set), len(test_set)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SggPQDwAE6hI","executionInfo":{"status":"ok","timestamp":1715621319014,"user_tz":-180,"elapsed":14,"user":{"displayName":"Anıl Özcan","userId":"06510389857538456980"}},"outputId":"972516c0-03bc-4bb4-9e17-c9fe70e19714"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(145, 18, 19)"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# Create data loaders\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size=16, shuffle=True)\n","val_loader = torch.utils.data.DataLoader(val_set, batch_size=8, shuffle=False)\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=8, shuffle=False)"],"metadata":{"id":"4Y5flypn6JEB","executionInfo":{"status":"ok","timestamp":1715621319014,"user_tz":-180,"elapsed":11,"user":{"displayName":"Anıl Özcan","userId":"06510389857538456980"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZF2eS6bHUUo8","executionInfo":{"status":"ok","timestamp":1715621319014,"user_tz":-180,"elapsed":10,"user":{"displayName":"Anıl Özcan","userId":"06510389857538456980"}},"outputId":"20ba4dfe-e1ab-4582-a6fe-8338f7d427a7"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3838"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["class CNN3D(nn.Module):\n","    def __init__(self, t_dim=30, img_x=120, img_y=120, drop_p=0.4, fc_hidden1=1024, fc_hidden2=128, num_output=2, send_device_fc=True):\n","        super(CNN3D, self).__init__()\n","\n","        # set video dimension\n","        self.t_dim = t_dim\n","        self.img_x = img_x\n","        self.img_y = img_y\n","        self.send_device_fc = send_device_fc\n","\n","        # fully connected layer hidden nodes\n","        self.fc_hidden1, self.fc_hidden2 = fc_hidden1, fc_hidden2\n","        self.drop_p = drop_p  # dropout probability\n","        self.num_output = num_output # Normal, Shoplifting\n","        self.ch1, self.ch2, self.ch3, self.ch4, self.ch5, self.ch6 = 8, 16, 32, 64, 96, 128\n","        self.k1, self.k2, self.k3, self.k4 = (3, 3, 3), (5, 5, 5), (7, 7, 7), (3, 1, 1)  # 3d kernel size\n","        self.s1, self.s2, self.s3 = (1, 1, 1), (2, 1, 1), (2, 2, 2)  # 3d strides\n","        self.pd1, self.pd2 = (0, 0, 0), (0, 0, 1)  # 3d padding\n","\n","        # Layer 0 - Shape\n","        #self.conv0_0_out = utils.conv3D_output_size((self.t_dim, self.img_x, self.img_y), self.pd1, self.k1, self.s1)\n","        #print(self.conv0_0_out)\n","        #self.conv0_1_out = utils.conv3D_output_size(self.conv0_0_out, self.pd1, self.k1, self.s1)\n","        #print(self.conv0_1_out)\n","        #self.conv0_2_out = utils.conv3D_output_size(self.conv0_1_out, self.pd1, self.k1, self.s1)\n","        #print(self.conv0_2_out)\n","        #self.pool0_3_out = utils.pooling_output_size(self.conv0_2_out, kernel_size=self.s3, stride=(1, 1, 1), padding=(0, 0, 0))\n","        #print(\"mp\")\n","        #print(self.pool0_3_out)\n","        #self.conv0_4_out = utils.conv3D_output_size(self.pool0_3_out, self.pd1, self.k1, self.s1)\n","        #print(self.conv0_4_out)\n","        #self.pool0_5_out = utils.pooling_output_size(self.conv0_4_out, kernel_size=self.s2, stride=(1, 1, 2), padding=(0, 0, 0))\n","        #print(\"mp\")\n","        #print(self.pool0_5_out)\n","        #self.conv0_6_out = utils.conv3D_output_size(self.pool0_5_out, self.pd1, self.k1, self.s1)\n","        #print(self.conv0_6_out)\n","        #self.conv0_7_out = utils.conv3D_output_size(self.conv0_6_out, self.pd1, self.k2, self.s1)\n","        #print(self.conv0_7_out)\n","        #self.conv0_8_out = utils.conv3D_output_size(self.conv0_7_out, self.pd1, self.k1, self.s1)\n","        #print(self.conv0_8_out)\n","        #self.conv0_9_out = utils.conv3D_output_size(self.conv0_8_out, self.pd1, self.k1, self.s1)\n","        #print(self.conv0_9_out)\n","        ## Layer 0 - Shape Cont.\n","        #self.conv0_12_out = utils.conv3D_output_size(self.conv0_9_out, self.pd1, self.k1, self.s1)\n","        #print(self.conv0_12_out)\n","        #self.conv0_13_out = utils.conv3D_output_size(self.conv0_12_out, self.pd1, self.k1, self.s1)\n","        #print(self.conv0_13_out)\n","        #self.pool0_14_out = utils.pooling_output_size(self.conv0_13_out, self.s3, (2, 2, 2), (0, 0, 0))\n","        #print(\"mp\")\n","        #print(self.pool0_14_out)\n","        ## Final Layer - Shape\n","        #self.conv3_2_out = utils.conv3D_output_size(self.pool0_14_out, self.pd1, self.k1, self.s1)\n","        #print(self.conv3_2_out)\n","        #self.conv3_3_out = utils.conv3D_output_size(self.conv3_2_out, self.pd1, self.k1, self.s1)\n","        #print(self.conv3_3_out)\n","\n","        # Layer 0\n","        self.conv0_0 = nn.Conv3d(in_channels=3, out_channels=self.ch1, kernel_size=self.k1, stride=self.s1,\n","                               padding=self.pd1)\n","\n","        self.conv0_1 = nn.Conv3d(in_channels=self.ch1, out_channels=self.ch2, kernel_size=self.k1, stride=self.s1,\n","                               padding=self.pd1)\n","\n","        self.conv0_2 = nn.Conv3d(in_channels=self.ch2, out_channels=self.ch2, kernel_size=self.k1, stride=self.s1,\n","                               padding=self.pd1)\n","        self.pool0_3 = nn.MaxPool3d(kernel_size = (2, 2, 2), stride = (1, 1, 1))\n","        self.conv0_4 = nn.Conv3d(in_channels=self.ch2, out_channels=self.ch2, kernel_size=self.k1, stride=self.s1,\n","                               padding=self.pd1)\n","        self.conv0_4_2 = nn.Conv3d(in_channels=self.ch2, out_channels=self.ch3, kernel_size=self.k1, stride=self.s1,\n","                               padding=self.pd1)\n","        self.pool0_5 = nn.MaxPool3d(kernel_size = (2, 1, 1), stride = (2, 1, 1)) # start point of parallel layers\n","        self.conv0_6 = nn.Conv3d(in_channels=self.ch2, out_channels=self.ch3, kernel_size=self.k1, stride=self.s1,\n","                               padding=self.pd1)\n","        self.conv0_7 = nn.Conv3d(in_channels=self.ch3, out_channels=self.ch3, kernel_size=self.k2, stride=self.s1,\n","                               padding=self.pd1)\n","        self.conv0_8 = nn.Conv3d(in_channels=self.ch3, out_channels=self.ch3, kernel_size=self.k1, stride=self.s1,\n","                               padding=self.pd1)\n","        self.conv0_9 = nn.Conv3d(in_channels=self.ch3, out_channels=self.ch3, kernel_size=self.k1, stride=self.s1,\n","                               padding=self.pd1)\n","        #print(\"Layer 0\")\n","        # 1st parallel layer\n","        self.conv1_0 = nn.Conv3d(in_channels=self.ch2, out_channels=self.ch3, kernel_size=self.k1, stride=self.s1,\n","                               padding=self.pd1)\n","        self.conv1_1 = nn.Conv3d(in_channels=self.ch3, out_channels=self.ch3, kernel_size=self.k3, stride=self.s1,\n","                               padding=self.pd1)\n","        self.conv1_2 = nn.Conv3d(in_channels=self.ch3, out_channels=self.ch3, kernel_size=self.k1, stride=self.s1,\n","                               padding=self.pd1)\n","\n","        #print(\"Layer 1\")\n","        # first concatination and batch normalisation\n","        self.bn0_11 = nn.BatchNorm3d(self.ch4)\n","        self.conv0_12 = nn.Conv3d(in_channels=self.ch4, out_channels=self.ch4, kernel_size=self.k1, stride=self.s1,\n","                               padding=self.pd1)\n","        self.conv0_13 = nn.Conv3d(in_channels=self.ch4, out_channels=self.ch4, kernel_size=self.k1, stride=self.s1,\n","                               padding=self.pd1)\n","        self.pool0_14 = nn.MaxPool3d(kernel_size = (2, 2, 2), stride = (2, 2, 2))\n","        #print(\"First Concat\")\n","\n","        # 2nd parallel layer\n","        self.conv2_0 = nn.Conv3d(in_channels=self.ch3, out_channels=self.ch3, kernel_size=self.k1, stride=self.s3,\n","                               padding=self.pd1)\n","        self.pool2_1 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(1, 1, 1))\n","        self.conv2_2 = nn.Conv3d(in_channels=self.ch3, out_channels=self.ch4, kernel_size=self.k1, stride=self.s1,\n","                               padding=self.pd1)\n","        self.conv2_3 = nn.Conv3d(in_channels=self.ch4, out_channels=self.ch4, kernel_size=self.k1, stride=self.s2,\n","                               padding=self.pd1)\n","        self.conv2_4 = nn.Conv3d(in_channels=self.ch4, out_channels=self.ch4, kernel_size=self.k4, stride=self.s2,\n","                               padding=self.pd1)\n","        self.pool2_5 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(1, 1, 1))\n","        #print(\"2nd Parallel\")\n","\n","        # last sequential layer\n","        self.bn3_1 = nn.BatchNorm3d(self.ch4)\n","        self.conv3_2 = nn.Conv3d(in_channels=self.ch4, out_channels=self.ch5, kernel_size=self.k1, stride=self.s1,\n","                               padding=self.pd2) # need to keep 3 time_dim\n","        self.conv3_3 = nn.Conv3d(in_channels=self.ch5, out_channels=self.ch5, kernel_size=self.k1, stride=self.s1,\n","                               padding=self.pd1)\n","        self.bn3_4 = nn.BatchNorm3d(self.ch5)\n","        #print(\"Last Sequential\")\n","\n","        ## Fully connected layes\n","        #print(self.ch5)\n","        #print(self.conv3_3_out[0])\n","        #print(self.conv3_3_out[1])\n","        #print(self.conv3_3_out[2])\n","\n","        self.fc2 = nn.Linear(self.fc_hidden1, self.fc_hidden2)\n","        self.fc3 = nn.Linear(self.fc_hidden2, self.num_output) # fully connected layer, output = binary_classes\n","\n","    def forward(self, x_3d):\n","        # Layer 0\n","        a = self.conv0_0(x_3d)\n","        #print(a.size())\n","        a = self.conv0_1(a)\n","        #print(a.size())\n","        a = self.conv0_2(a)\n","        #print(a.size())\n","        #print(\"mp\")\n","        a = self.pool0_3(a)\n","        #print(a.size())\n","        a = self.conv0_4(a)\n","        #print(a.size())\n","        c = self.conv0_4_2(a)\n","        #print(c.size())\n","        a = self.pool0_5(a)\n","        #print(\"mp\")\n","        #print(a.size())\n","        b = a\n","        a = self.conv0_6(a)\n","        #print(a.size())\n","        a = self.conv0_7(a)\n","        #print(a.size())\n","        a = self.conv0_8(a)\n","        #print(a.size())\n","        a = self.conv0_9(a)\n","        #print(a.size())\n","\n","        # Layer 1\n","        #print(\"b\")\n","        b = self.conv1_0(b)\n","        #print(b.size())\n","        b = self.conv1_1(b)\n","        #print(b.size())\n","        b = self.conv1_2(b)\n","        #print(b.size())\n","\n","        # Layer 0 - 1 merge\n","        #print(\"ab\")\n","        ab = torch.cat([a, b], dim=1)\n","        #print(ab.size())\n","        ab = self.bn0_11(ab)\n","        #print(ab.size())\n","        ab = self.conv0_12(ab)\n","        #print(ab.size())\n","        ab = self.conv0_13(ab)\n","        #print(ab.size())\n","        ab = self.pool0_14(ab)\n","        #print(ab.size())\n","\n","        # Layer 2\n","        #print(\"c\")\n","        c = self.conv2_0(c)\n","        #print(c.size())\n","        c = self.pool2_1(c)\n","        #print(c.size())\n","        c = self.conv2_2(c)\n","        #print(c.size())\n","        c = self.conv2_3(c)\n","        #print(c.size())\n","        c = self.conv2_4(c)\n","        #print(c.size())\n","        c = self.pool2_5(c)\n","        #print(c.size())\n","\n","        # Layer 0 - 1 - 2 merge\n","        #print(\"abc\")\n","        abc = torch.cat([ab, c], dim=2)\n","        #print(abc.size())\n","        abc = self.bn3_1(abc)\n","        #print(abc.size())\n","        abc = self.conv3_2(abc)\n","        #print(abc.size())\n","        abc = self.conv3_3(abc)\n","        #print(abc.size())\n","        abc = self.bn3_4(abc)\n","        #print(abc.size())\n","\n","\n","        # Dropout & fully connected layers\n","        abc = abc.view(abc.size(0), -1)\n","        #print(abc.size())\n","        abc = F.dropout(abc, p=self.drop_p, training=self.training)\n","        #print(abc.size()[1])\n","        if self.send_device_fc: # Handler for GPU-CPU confusion\n","          fc1 = nn.Linear(abc.size()[1], self.fc_hidden1) # fully connected hidden layer\n","          fc1.to(device)\n","          abc = fc1(abc)\n","        else:\n","          abc = nn.Linear(abc.size()[1], self.fc_hidden1)(abc)  # fully connected hidden layer\n","\n","        #print(abc.size())\n","        abc = F.dropout(abc, p=self.drop_p, training=self.training)\n","        #print(abc.size())\n","        abc = self.fc2(abc)\n","        #print(abc.size())\n","        abc = F.dropout(abc, p=self.drop_p, training=self.training)\n","        #print(abc.size())\n","        abc = self.fc3(abc)\n","        #print(abc.size())\n","        output = F.softmax(abc, dim=1)\n","        #print(output.size())\n","\n","        return output"],"metadata":{"id":"qEA70b-3nkYx","executionInfo":{"status":"ok","timestamp":1715621319014,"user_tz":-180,"elapsed":9,"user":{"displayName":"Anıl Özcan","userId":"06510389857538456980"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Let's create an instance of the model and print its architecture\n","model = CNN3D(t_dim=30, img_x=120, img_y=120, drop_p=0.4, fc_hidden1=1024, fc_hidden2=128, num_output=2, send_device_fc=False)\n","print(model)\n","\n","# Define the shape of the dummy input data (batch_size, channels, frames, height, width)\n","dummy_input_shape = (32, 3, 120, 120, 30) # Batch size 32, 3 input channels, 16 frames, 112x112 resolution\n","\n","# Generate random dummy input data within the defined shape\n","dummy_input = torch.randn(*dummy_input_shape)\n","\n","# Forward pass through the model\n","output = model(dummy_input)\n","\n","# Print the output shape\n","print(\"Output shape:\", output.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P52N0spwhwas","executionInfo":{"status":"ok","timestamp":1715621379000,"user_tz":-180,"elapsed":23492,"user":{"displayName":"Anıl Özcan","userId":"06510389857538456980"}},"outputId":"8b408c47-ca5f-4655-8187-f05bfbe645e7","collapsed":true},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["CNN3D(\n","  (conv0_0): Conv3d(3, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n","  (conv0_1): Conv3d(8, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n","  (conv0_2): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n","  (pool0_3): MaxPool3d(kernel_size=(2, 2, 2), stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n","  (conv0_4): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n","  (conv0_4_2): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n","  (pool0_5): MaxPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0, dilation=1, ceil_mode=False)\n","  (conv0_6): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n","  (conv0_7): Conv3d(32, 32, kernel_size=(5, 5, 5), stride=(1, 1, 1))\n","  (conv0_8): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n","  (conv0_9): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n","  (conv1_0): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n","  (conv1_1): Conv3d(32, 32, kernel_size=(7, 7, 7), stride=(1, 1, 1))\n","  (conv1_2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n","  (bn0_11): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv0_12): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n","  (conv0_13): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n","  (pool0_14): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n","  (conv2_0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2))\n","  (pool2_1): MaxPool3d(kernel_size=(2, 2, 2), stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n","  (conv2_2): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n","  (conv2_3): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(2, 1, 1))\n","  (conv2_4): Conv3d(64, 64, kernel_size=(3, 1, 1), stride=(2, 1, 1))\n","  (pool2_5): MaxPool3d(kernel_size=(2, 2, 2), stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n","  (bn3_1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv3_2): Conv3d(64, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 0, 1))\n","  (conv3_3): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n","  (bn3_4): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (fc2): Linear(in_features=1024, out_features=128, bias=True)\n","  (fc3): Linear(in_features=128, out_features=2, bias=True)\n",")\n","Output shape: torch.Size([32, 2])\n"]}]},{"cell_type":"code","source":["summary(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-_pk6TYaX-lc","executionInfo":{"status":"ok","timestamp":1715621379000,"user_tz":-180,"elapsed":29,"user":{"displayName":"Anıl Özcan","userId":"06510389857538456980"}},"outputId":"a8c8b72b-01a3-453c-c5a4-f2b69f730b67","collapsed":true},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["=================================================================\n","Layer (type:depth-idx)                   Param #\n","=================================================================\n","CNN3D                                    --\n","├─Conv3d: 1-1                            656\n","├─Conv3d: 1-2                            3,472\n","├─Conv3d: 1-3                            6,928\n","├─MaxPool3d: 1-4                         --\n","├─Conv3d: 1-5                            6,928\n","├─Conv3d: 1-6                            13,856\n","├─MaxPool3d: 1-7                         --\n","├─Conv3d: 1-8                            13,856\n","├─Conv3d: 1-9                            128,032\n","├─Conv3d: 1-10                           27,680\n","├─Conv3d: 1-11                           27,680\n","├─Conv3d: 1-12                           13,856\n","├─Conv3d: 1-13                           351,264\n","├─Conv3d: 1-14                           27,680\n","├─BatchNorm3d: 1-15                      128\n","├─Conv3d: 1-16                           110,656\n","├─Conv3d: 1-17                           110,656\n","├─MaxPool3d: 1-18                        --\n","├─Conv3d: 1-19                           27,680\n","├─MaxPool3d: 1-20                        --\n","├─Conv3d: 1-21                           55,360\n","├─Conv3d: 1-22                           110,656\n","├─Conv3d: 1-23                           12,352\n","├─MaxPool3d: 1-24                        --\n","├─BatchNorm3d: 1-25                      128\n","├─Conv3d: 1-26                           165,984\n","├─Conv3d: 1-27                           248,928\n","├─BatchNorm3d: 1-28                      192\n","├─Linear: 1-29                           131,200\n","├─Linear: 1-30                           258\n","=================================================================\n","Total params: 1,596,066\n","Trainable params: 1,596,066\n","Non-trainable params: 0\n","================================================================="]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["model = CNN3D(t_dim=30, img_x=120, img_y=120, drop_p=0.4, fc_hidden1=1024, fc_hidden2=128, num_output=2, send_device_fc=True)"],"metadata":{"collapsed":true,"id":"cWS8uDjXrA7e","executionInfo":{"status":"ok","timestamp":1715621379000,"user_tz":-180,"elapsed":25,"user":{"displayName":"Anıl Özcan","userId":"06510389857538456980"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# hyper-params\n","num_epochs = 100\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# dont forget to send model to device\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4xsO_euHyj_z","executionInfo":{"status":"ok","timestamp":1715621379890,"user_tz":-180,"elapsed":911,"user":{"displayName":"Anıl Özcan","userId":"06510389857538456980"}},"outputId":"97892757-c5a8-4ee4-e2fe-f482f53d705d"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["CNN3D(\n","  (conv0_0): Conv3d(3, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n","  (conv0_1): Conv3d(8, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n","  (conv0_2): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n","  (pool0_3): MaxPool3d(kernel_size=(2, 2, 2), stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n","  (conv0_4): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n","  (conv0_4_2): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n","  (pool0_5): MaxPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0, dilation=1, ceil_mode=False)\n","  (conv0_6): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n","  (conv0_7): Conv3d(32, 32, kernel_size=(5, 5, 5), stride=(1, 1, 1))\n","  (conv0_8): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n","  (conv0_9): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n","  (conv1_0): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n","  (conv1_1): Conv3d(32, 32, kernel_size=(7, 7, 7), stride=(1, 1, 1))\n","  (conv1_2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n","  (bn0_11): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv0_12): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n","  (conv0_13): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n","  (pool0_14): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n","  (conv2_0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2))\n","  (pool2_1): MaxPool3d(kernel_size=(2, 2, 2), stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n","  (conv2_2): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n","  (conv2_3): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(2, 1, 1))\n","  (conv2_4): Conv3d(64, 64, kernel_size=(3, 1, 1), stride=(2, 1, 1))\n","  (pool2_5): MaxPool3d(kernel_size=(2, 2, 2), stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n","  (bn3_1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv3_2): Conv3d(64, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 0, 1))\n","  (conv3_3): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n","  (bn3_4): BatchNorm3d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (fc2): Linear(in_features=1024, out_features=128, bias=True)\n","  (fc3): Linear(in_features=128, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["# Training loop\n","best_acc = 0\n","history = {\"epochs\": [],\n","           \"train_loss\": [],\n","           \"val_loss\": [],\n","           \"val_acc\": []\n","           }\n","\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    for inputs, targets in train_loader:\n","        inputs, targets = inputs.to(device, dtype=torch.float32), targets.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item() * inputs.size(0)\n","\n","    # Validation loop\n","    model.eval()\n","    val_loss = 0.0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for inputs, targets in val_loader:\n","            inputs, targets = inputs.to(device, dtype=torch.float32), targets.to(device)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, targets)\n","            val_loss += loss.item() * inputs.size(0)\n","            _, predicted = outputs.max(1)\n","            total += targets.size(0)\n","            correct += predicted.eq(targets).sum().item()\n","\n","    if (100 * correct / total) > best_acc:\n","      best_acc = 100 * correct / total\n","      best_model_wts = deepcopy(model.state_dict())\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n","          f\"Train Loss: {running_loss / len(train_loader.dataset):.4f}, \"\n","          f\"Val Loss: {val_loss / len(val_loader.dataset):.4f}, \"\n","          f\"Val Acc: {(100 * correct / total):.2f}%\")\n","    history[\"epochs\"].append(epoch)\n","    history[\"train_loss\"].append(running_loss / len(train_loader.dataset))\n","    history[\"val_loss\"].append(val_loss / len(val_loader.dataset))\n","    history[\"val_acc\"].append((100 * correct / total))\n","\n","\n","# Testing loop\n","model.eval()\n","test_loss = 0.0\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for inputs, targets in test_loader:\n","        inputs, targets = inputs.to(device, dtype=torch.float32), targets.to(device)\n","        outputs = model(inputs)\n","        loss = criterion(outputs, targets)\n","        test_loss += loss.item() * inputs.size(0)\n","        _, predicted = outputs.max(1)\n","        total += targets.size(0)\n","        correct += predicted.eq(targets).sum().item()\n","\n","print(f\"Test Loss: {test_loss / len(test_loader.dataset):.4f}, \"\n","      f\"Test Acc: {(100 * correct / total):.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"ElcnaiPvi1bh","outputId":"d32850b1-f9f8-4089-be3d-ac580dc9638e","executionInfo":{"status":"ok","timestamp":1715633709655,"user_tz":-180,"elapsed":389660,"user":{"displayName":"Anıl Özcan","userId":"06510389857538456980"}}},"execution_count":22,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torchvision/io/video.py:161: UserWarning: The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\n","  warnings.warn(\"The pts_unit 'pts' gives wrong results. Please use pts_unit 'sec'.\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/100], Train Loss: 0.7250, Val Loss: 0.7544, Val Acc: 55.56%\n","Epoch [2/100], Train Loss: 0.7255, Val Loss: 0.7009, Val Acc: 50.00%\n","Epoch [3/100], Train Loss: 0.7190, Val Loss: 0.7896, Val Acc: 44.44%\n","Epoch [4/100], Train Loss: 0.7188, Val Loss: 0.7063, Val Acc: 33.33%\n","Epoch [5/100], Train Loss: 0.7354, Val Loss: 0.7113, Val Acc: 55.56%\n","Epoch [6/100], Train Loss: 0.6957, Val Loss: 0.6838, Val Acc: 55.56%\n","Epoch [7/100], Train Loss: 0.7355, Val Loss: 0.7346, Val Acc: 44.44%\n","Epoch [8/100], Train Loss: 0.7384, Val Loss: 0.7375, Val Acc: 44.44%\n","Epoch [9/100], Train Loss: 0.7302, Val Loss: 0.7067, Val Acc: 55.56%\n","Epoch [10/100], Train Loss: 0.7117, Val Loss: 0.7019, Val Acc: 55.56%\n","Epoch [11/100], Train Loss: 0.7211, Val Loss: 0.7069, Val Acc: 38.89%\n","Epoch [12/100], Train Loss: 0.6902, Val Loss: 0.6777, Val Acc: 55.56%\n","Epoch [13/100], Train Loss: 0.6991, Val Loss: 0.6943, Val Acc: 55.56%\n","Epoch [14/100], Train Loss: 0.7479, Val Loss: 0.6856, Val Acc: 55.56%\n","Epoch [15/100], Train Loss: 0.6958, Val Loss: 0.7050, Val Acc: 44.44%\n","Epoch [16/100], Train Loss: 0.7000, Val Loss: 0.6858, Val Acc: 50.00%\n","Epoch [17/100], Train Loss: 0.7381, Val Loss: 0.7133, Val Acc: 44.44%\n","Epoch [18/100], Train Loss: 0.7337, Val Loss: 0.7191, Val Acc: 44.44%\n","Epoch [19/100], Train Loss: 0.7266, Val Loss: 0.6818, Val Acc: 55.56%\n","Epoch [20/100], Train Loss: 0.7441, Val Loss: 0.7140, Val Acc: 38.89%\n","Epoch [21/100], Train Loss: 0.6974, Val Loss: 0.6935, Val Acc: 55.56%\n","Epoch [22/100], Train Loss: 0.7018, Val Loss: 0.6959, Val Acc: 55.56%\n","Epoch [23/100], Train Loss: 0.7394, Val Loss: 0.7035, Val Acc: 38.89%\n","Epoch [24/100], Train Loss: 0.7076, Val Loss: 0.6948, Val Acc: 55.56%\n","Epoch [25/100], Train Loss: 0.6955, Val Loss: 0.7095, Val Acc: 44.44%\n","Epoch [26/100], Train Loss: 0.7089, Val Loss: 0.7119, Val Acc: 44.44%\n","Epoch [27/100], Train Loss: 0.7224, Val Loss: 0.7267, Val Acc: 44.44%\n","Epoch [28/100], Train Loss: 0.6787, Val Loss: 0.6988, Val Acc: 44.44%\n","Epoch [29/100], Train Loss: 0.6865, Val Loss: 0.7249, Val Acc: 44.44%\n","Epoch [30/100], Train Loss: 0.6835, Val Loss: 0.6838, Val Acc: 55.56%\n","Epoch [31/100], Train Loss: 0.7605, Val Loss: 0.6912, Val Acc: 55.56%\n","Epoch [32/100], Train Loss: 0.7002, Val Loss: 0.6907, Val Acc: 55.56%\n","Epoch [33/100], Train Loss: 0.7340, Val Loss: 0.7239, Val Acc: 44.44%\n","Epoch [34/100], Train Loss: 0.6973, Val Loss: 0.6876, Val Acc: 55.56%\n","Epoch [35/100], Train Loss: 0.6908, Val Loss: 0.6724, Val Acc: 55.56%\n","Epoch [36/100], Train Loss: 0.7094, Val Loss: 0.7407, Val Acc: 44.44%\n","Epoch [37/100], Train Loss: 0.7140, Val Loss: 0.6878, Val Acc: 55.56%\n","Epoch [38/100], Train Loss: 0.7286, Val Loss: 0.6876, Val Acc: 55.56%\n","Epoch [39/100], Train Loss: 0.7179, Val Loss: 0.6889, Val Acc: 50.00%\n","Epoch [40/100], Train Loss: 0.7049, Val Loss: 0.6808, Val Acc: 55.56%\n","Epoch [41/100], Train Loss: 0.6951, Val Loss: 0.7041, Val Acc: 44.44%\n","Epoch [42/100], Train Loss: 0.6873, Val Loss: 0.7029, Val Acc: 44.44%\n","Epoch [43/100], Train Loss: 0.7202, Val Loss: 0.6918, Val Acc: 55.56%\n","Epoch [44/100], Train Loss: 0.7398, Val Loss: 0.7316, Val Acc: 44.44%\n","Epoch [45/100], Train Loss: 0.7055, Val Loss: 0.6855, Val Acc: 55.56%\n","Epoch [46/100], Train Loss: 0.7147, Val Loss: 0.6969, Val Acc: 44.44%\n","Epoch [47/100], Train Loss: 0.7116, Val Loss: 0.6950, Val Acc: 55.56%\n","Epoch [48/100], Train Loss: 0.7281, Val Loss: 0.7037, Val Acc: 44.44%\n","Epoch [49/100], Train Loss: 0.7094, Val Loss: 0.6948, Val Acc: 44.44%\n","Epoch [50/100], Train Loss: 0.6975, Val Loss: 0.6887, Val Acc: 55.56%\n","Epoch [51/100], Train Loss: 0.6937, Val Loss: 0.7139, Val Acc: 44.44%\n","Epoch [52/100], Train Loss: 0.6870, Val Loss: 0.6824, Val Acc: 55.56%\n","Epoch [53/100], Train Loss: 0.6925, Val Loss: 0.6911, Val Acc: 44.44%\n","Epoch [54/100], Train Loss: 0.6911, Val Loss: 0.6883, Val Acc: 61.11%\n","Epoch [55/100], Train Loss: 0.7215, Val Loss: 0.6816, Val Acc: 66.67%\n","Epoch [56/100], Train Loss: 0.7015, Val Loss: 0.6985, Val Acc: 38.89%\n","Epoch [57/100], Train Loss: 0.6983, Val Loss: 0.6853, Val Acc: 55.56%\n","Epoch [58/100], Train Loss: 0.7056, Val Loss: 0.6810, Val Acc: 61.11%\n","Epoch [59/100], Train Loss: 0.7211, Val Loss: 0.6817, Val Acc: 55.56%\n","Epoch [60/100], Train Loss: 0.6920, Val Loss: 0.6837, Val Acc: 55.56%\n","Epoch [61/100], Train Loss: 0.6939, Val Loss: 0.6926, Val Acc: 55.56%\n","Epoch [62/100], Train Loss: 0.7239, Val Loss: 0.6850, Val Acc: 55.56%\n","Epoch [63/100], Train Loss: 0.7002, Val Loss: 0.7011, Val Acc: 44.44%\n","Epoch [64/100], Train Loss: 0.7097, Val Loss: 0.6884, Val Acc: 55.56%\n","Epoch [65/100], Train Loss: 0.7078, Val Loss: 0.7183, Val Acc: 44.44%\n","Epoch [66/100], Train Loss: 0.6989, Val Loss: 0.7014, Val Acc: 50.00%\n","Epoch [67/100], Train Loss: 0.6984, Val Loss: 0.7025, Val Acc: 44.44%\n","Epoch [68/100], Train Loss: 0.6953, Val Loss: 0.6801, Val Acc: 55.56%\n","Epoch [69/100], Train Loss: 0.6942, Val Loss: 0.7485, Val Acc: 44.44%\n","Epoch [70/100], Train Loss: 0.6791, Val Loss: 0.7002, Val Acc: 44.44%\n","Epoch [71/100], Train Loss: 0.6937, Val Loss: 0.7094, Val Acc: 44.44%\n","Epoch [72/100], Train Loss: 0.7073, Val Loss: 0.6851, Val Acc: 61.11%\n","Epoch [73/100], Train Loss: 0.7142, Val Loss: 0.7025, Val Acc: 44.44%\n","Epoch [74/100], Train Loss: 0.6874, Val Loss: 0.7043, Val Acc: 44.44%\n","Epoch [75/100], Train Loss: 0.6900, Val Loss: 0.6835, Val Acc: 55.56%\n","Epoch [76/100], Train Loss: 0.7081, Val Loss: 0.6973, Val Acc: 44.44%\n","Epoch [77/100], Train Loss: 0.7105, Val Loss: 0.7150, Val Acc: 44.44%\n","Epoch [78/100], Train Loss: 0.7070, Val Loss: 0.6857, Val Acc: 55.56%\n","Epoch [79/100], Train Loss: 0.7057, Val Loss: 0.7041, Val Acc: 44.44%\n","Epoch [80/100], Train Loss: 0.6955, Val Loss: 0.7017, Val Acc: 44.44%\n","Epoch [81/100], Train Loss: 0.7017, Val Loss: 0.7014, Val Acc: 50.00%\n","Epoch [82/100], Train Loss: 0.7038, Val Loss: 0.7175, Val Acc: 44.44%\n","Epoch [83/100], Train Loss: 0.6979, Val Loss: 0.6999, Val Acc: 55.56%\n","Epoch [84/100], Train Loss: 0.7089, Val Loss: 0.7158, Val Acc: 44.44%\n","Epoch [85/100], Train Loss: 0.6917, Val Loss: 0.7154, Val Acc: 44.44%\n","Epoch [86/100], Train Loss: 0.6918, Val Loss: 0.7136, Val Acc: 44.44%\n","Epoch [87/100], Train Loss: 0.6804, Val Loss: 0.6964, Val Acc: 55.56%\n","Epoch [88/100], Train Loss: 0.7144, Val Loss: 0.7039, Val Acc: 44.44%\n","Epoch [89/100], Train Loss: 0.6826, Val Loss: 0.6832, Val Acc: 44.44%\n","Epoch [90/100], Train Loss: 0.6781, Val Loss: 0.7135, Val Acc: 44.44%\n","Epoch [91/100], Train Loss: 0.6859, Val Loss: 0.7125, Val Acc: 55.56%\n","Epoch [92/100], Train Loss: 0.7048, Val Loss: 0.6934, Val Acc: 44.44%\n","Epoch [93/100], Train Loss: 0.6865, Val Loss: 0.6912, Val Acc: 55.56%\n","Epoch [94/100], Train Loss: 0.7213, Val Loss: 0.6911, Val Acc: 55.56%\n","Epoch [95/100], Train Loss: 0.7007, Val Loss: 0.7201, Val Acc: 44.44%\n","Epoch [96/100], Train Loss: 0.6886, Val Loss: 0.6808, Val Acc: 55.56%\n","Epoch [97/100], Train Loss: 0.7163, Val Loss: 0.7005, Val Acc: 55.56%\n","Epoch [98/100], Train Loss: 0.6957, Val Loss: 0.7138, Val Acc: 50.00%\n","Epoch [99/100], Train Loss: 0.6899, Val Loss: 0.6971, Val Acc: 55.56%\n","Epoch [100/100], Train Loss: 0.7248, Val Loss: 0.7108, Val Acc: 44.44%\n","Test Loss: 0.7043, Test Acc: 42.11%\n"]}]}]}